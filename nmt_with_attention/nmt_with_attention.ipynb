{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_qNSzzyaCbD"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "jmjh290raIky"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0Qjg6vuaHNt"
   },
   "source": [
    "# Neural machine translation with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AOpGoE2T-YXS"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">\n",
    "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
    "    View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/nmt_with_attention.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/nmt_with_attention.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/text/nmt_with_attention.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CiwtNgENbx2g"
   },
   "source": [
    "This notebook trains a sequence to sequence (seq2seq) model for Spanish to English translation. This is an advanced example that assumes some knowledge of sequence to sequence models.\n",
    "\n",
    "After training the model in this notebook, you will be able to input a Spanish sentence, such as *\"¿todavia estan en casa?\"*, and return the English translation: *\"are you still at home?\"*\n",
    "\n",
    "The translation quality is reasonable for a toy example, but the generated attention plot is perhaps more interesting. This shows which parts of the input sentence has the model's attention while translating:\n",
    "\n",
    "<img src=\"https://tensorflow.org/images/spanish-english.png\" alt=\"spanish-english attention plot\">\n",
    "\n",
    "Note: This example takes approximately 10 mintues to run on a single P100 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnxXKDjq3jEL"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wfodePkj3jEa"
   },
   "source": [
    "## Download and prepare the dataset\n",
    "\n",
    "We'll use a language dataset provided by http://www.manythings.org/anki/. This dataset contains language translation pairs in the format:\n",
    "\n",
    "```\n",
    "May I borrow this book?\t¿Puedo tomar prestado este libro?\n",
    "```\n",
    "\n",
    "There are a variety of languages available, but we'll use the English-Spanish dataset. For convenience, we've hosted a copy of this dataset on Google Cloud, but you can also download your own copy. After downloading the dataset, here are the steps we'll take to prepare the data:\n",
    "\n",
    "1. Add a *start* and *end* token to each sentence.\n",
    "2. Clean the sentences by removing special characters.\n",
    "3. Create a word index and reverse word index (dictionaries mapping from word → id and id → word).\n",
    "4. Pad each sentence to a maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kRVATYOgJs1b"
   },
   "outputs": [],
   "source": [
    "# Download the file\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rd0jw-eC3jEh"
   },
   "outputs": [],
   "source": [
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "    w = w.rstrip().strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "opI2GzOt479E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHn4Dct23jEm"
   },
   "outputs": [],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "\n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTbSbBz55QtF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
      "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
     ]
    }
   ],
   "source": [
    "en, sp = create_dataset(path_to_file, None)\n",
    "print(en[-1])\n",
    "print(sp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OmMZQpdO60dt"
   },
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bIOn8RCNDJXG"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eAY9k49G3jE_"
   },
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "    # creating cleaned input, output pairs\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOi42V79Ydlr"
   },
   "source": [
    "### Limit the size of the dataset to experiment faster (optional)\n",
    "\n",
    "Training on the complete dataset of >100,000 sentences will take a long time. To train faster, we can limit the size of the dataset to 30,000 sentences (of course, translation quality degrades with less data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cnxC7q-j3jFD"
   },
   "outputs": [],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 30000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<start>': 1,\n",
       " '<end>': 2,\n",
       " '.': 3,\n",
       " 'tom': 4,\n",
       " '?': 5,\n",
       " '¿': 6,\n",
       " 'es': 7,\n",
       " 'no': 8,\n",
       " 'el': 9,\n",
       " 'a': 10,\n",
       " 'que': 11,\n",
       " 'me': 12,\n",
       " 'la': 13,\n",
       " 'de': 14,\n",
       " 'un': 15,\n",
       " 'esta': 16,\n",
       " 'se': 17,\n",
       " 'lo': 18,\n",
       " 'mi': 19,\n",
       " 'en': 20,\n",
       " 'una': 21,\n",
       " 'por': 22,\n",
       " 'te': 23,\n",
       " 'estoy': 24,\n",
       " 'ella': 25,\n",
       " 'yo': 26,\n",
       " '!': 27,\n",
       " 'eso': 28,\n",
       " 'le': 29,\n",
       " 'esto': 30,\n",
       " 'tu': 31,\n",
       " ',': 32,\n",
       " 'los': 33,\n",
       " 'aqui': 34,\n",
       " 'soy': 35,\n",
       " 'muy': 36,\n",
       " 'tengo': 37,\n",
       " 'puedo': 38,\n",
       " 'las': 39,\n",
       " 'gusta': 40,\n",
       " 'mary': 41,\n",
       " 'tiene': 42,\n",
       " 'son': 43,\n",
       " 'con': 44,\n",
       " 'como': 45,\n",
       " 'quien': 46,\n",
       " 'estaba': 47,\n",
       " 'su': 48,\n",
       " 'este': 49,\n",
       " 'favor': 50,\n",
       " 'estas': 51,\n",
       " 'eres': 52,\n",
       " 'quiero': 53,\n",
       " 'ellos': 54,\n",
       " 'fue': 55,\n",
       " 'bien': 56,\n",
       " 'casa': 57,\n",
       " 'ahora': 58,\n",
       " 'tomas': 59,\n",
       " 'donde': 60,\n",
       " 'mas': 61,\n",
       " 'estan': 62,\n",
       " 'nos': 63,\n",
       " 'he': 64,\n",
       " 'solo': 65,\n",
       " 'puede': 66,\n",
       " 'ha': 67,\n",
       " 'era': 68,\n",
       " 'todos': 69,\n",
       " 'al': 70,\n",
       " 'para': 71,\n",
       " 'ir': 72,\n",
       " 'tan': 73,\n",
       " 'todo': 74,\n",
       " 'estamos': 75,\n",
       " 'necesito': 76,\n",
       " 'ya': 77,\n",
       " 'nadie': 78,\n",
       " 'puedes': 79,\n",
       " 'trabajo': 80,\n",
       " 'voy': 81,\n",
       " 'usted': 82,\n",
       " 'tienes': 83,\n",
       " 'demasiado': 84,\n",
       " 'ese': 85,\n",
       " 'nada': 86,\n",
       " 'y': 87,\n",
       " 'hay': 88,\n",
       " 'mucho': 89,\n",
       " 'nunca': 90,\n",
       " 'hizo': 91,\n",
       " 'perro': 92,\n",
       " 'esa': 93,\n",
       " 'algo': 94,\n",
       " 'libro': 95,\n",
       " 'hoy': 96,\n",
       " 'poco': 97,\n",
       " 'dos': 98,\n",
       " 'parece': 99,\n",
       " 'todavia': 100,\n",
       " 'dinero': 101,\n",
       " 'tiempo': 102,\n",
       " 'nuevo': 103,\n",
       " 'sabe': 104,\n",
       " 'somos': 105,\n",
       " 'quiere': 106,\n",
       " 'mis': 107,\n",
       " 'gustan': 108,\n",
       " 'ser': 109,\n",
       " 'nosotros': 110,\n",
       " 'vez': 111,\n",
       " 'coche': 112,\n",
       " 'estar': 113,\n",
       " 'sos': 114,\n",
       " 'feliz': 115,\n",
       " 'va': 116,\n",
       " 'buen': 117,\n",
       " 'tarde': 118,\n",
       " 'ti': 119,\n",
       " 'ahi': 120,\n",
       " 'frances': 121,\n",
       " 'hablar': 122,\n",
       " 'hacer': 123,\n",
       " 'verdad': 124,\n",
       " 'hace': 125,\n",
       " 'creo': 126,\n",
       " 'tenemos': 127,\n",
       " 'ayuda': 128,\n",
       " 'alli': 129,\n",
       " 'boston': 130,\n",
       " 'hombre': 131,\n",
       " 'has': 132,\n",
       " 'deja': 133,\n",
       " 'vi': 134,\n",
       " 've': 135,\n",
       " 'mal': 136,\n",
       " 'alguien': 137,\n",
       " 'auto': 138,\n",
       " 'vamos': 139,\n",
       " 'si': 140,\n",
       " 'mejor': 141,\n",
       " 'siento': 142,\n",
       " 'podria': 143,\n",
       " 'podemos': 144,\n",
       " 'cuando': 145,\n",
       " 'hice': 146,\n",
       " 'vida': 147,\n",
       " 'odio': 148,\n",
       " 'dia': 149,\n",
       " 'conmigo': 150,\n",
       " 'siempre': 151,\n",
       " 'les': 152,\n",
       " 'encanta': 153,\n",
       " 'otra': 154,\n",
       " 'dejame': 155,\n",
       " 'rapido': 156,\n",
       " 'cual': 157,\n",
       " 'ustedes': 158,\n",
       " 'vino': 159,\n",
       " 'tenia': 160,\n",
       " 'puerta': 161,\n",
       " 'bueno': 162,\n",
       " 'ver': 163,\n",
       " 'hacerlo': 164,\n",
       " 'ven': 165,\n",
       " 'tambien': 166,\n",
       " 'os': 167,\n",
       " 'comer': 168,\n",
       " 'buena': 169,\n",
       " 'sus': 170,\n",
       " 'deberia': 171,\n",
       " 'dijo': 172,\n",
       " 'listo': 173,\n",
       " 'padre': 174,\n",
       " 'habitacion': 175,\n",
       " 'habla': 176,\n",
       " 'nuestro': 177,\n",
       " 'realmente': 178,\n",
       " 'ayudar': 179,\n",
       " 'queria': 180,\n",
       " 'hecho': 181,\n",
       " 'mismo': 182,\n",
       " 'nadar': 183,\n",
       " 'cansado': 184,\n",
       " 'ocupado': 185,\n",
       " 'del': 186,\n",
       " 'acabo': 187,\n",
       " 'razon': 188,\n",
       " 'grande': 189,\n",
       " 'noche': 190,\n",
       " 'gracias': 191,\n",
       " 'mira': 192,\n",
       " 'gato': 193,\n",
       " 'miedo': 194,\n",
       " 'manana': 195,\n",
       " 'acuerdo': 196,\n",
       " 'debo': 197,\n",
       " 'cama': 198,\n",
       " 'dije': 199,\n",
       " 'tus': 200,\n",
       " 'espera': 201,\n",
       " 'visto': 202,\n",
       " 'mio': 203,\n",
       " 'tal': 204,\n",
       " 'bastante': 205,\n",
       " 'alto': 206,\n",
       " 'veo': 207,\n",
       " 'ellas': 208,\n",
       " 'necesita': 209,\n",
       " 'dame': 210,\n",
       " 'idea': 211,\n",
       " 'amigos': 212,\n",
       " 'hemos': 213,\n",
       " 'quieres': 214,\n",
       " 'pareces': 215,\n",
       " 'casi': 216,\n",
       " 'estado': 217,\n",
       " 'fui': 218,\n",
       " 'hambre': 219,\n",
       " 'dio': 220,\n",
       " 'agua': 221,\n",
       " 'sabes': 222,\n",
       " 'sabia': 223,\n",
       " 'uno': 224,\n",
       " 'comida': 225,\n",
       " 'problema': 226,\n",
       " 'facil': 227,\n",
       " 'frio': 228,\n",
       " 'fuera': 229,\n",
       " 'lunes': 230,\n",
       " 'amigo': 231,\n",
       " 'duele': 232,\n",
       " 'dejo': 233,\n",
       " 'conozco': 234,\n",
       " 'estos': 235,\n",
       " 'vio': 236,\n",
       " 'madre': 237,\n",
       " 'pronto': 238,\n",
       " 'anos': 239,\n",
       " 'nino': 240,\n",
       " 'loco': 241,\n",
       " 'haz': 242,\n",
       " 'dormir': 243,\n",
       " 'libros': 244,\n",
       " 'puso': 245,\n",
       " 'mano': 246,\n",
       " 'sin': 247,\n",
       " 'television': 248,\n",
       " 'vive': 249,\n",
       " 'ojos': 250,\n",
       " 'menos': 251,\n",
       " 'cantar': 252,\n",
       " 'estuvo': 253,\n",
       " 'hora': 254,\n",
       " 'enfermo': 255,\n",
       " 'amo': 256,\n",
       " 'seguro': 257,\n",
       " 'mundo': 258,\n",
       " 'tienen': 259,\n",
       " 'pelo': 260,\n",
       " 'murio': 261,\n",
       " 'perros': 262,\n",
       " 'perdido': 263,\n",
       " 'joven': 264,\n",
       " 'compre': 265,\n",
       " 'mujer': 266,\n",
       " 'maria': 267,\n",
       " 'nombre': 268,\n",
       " 'contigo': 269,\n",
       " 'viejo': 270,\n",
       " 'hablo': 271,\n",
       " 'triste': 272,\n",
       " 'entrar': 273,\n",
       " 'espero': 274,\n",
       " 'sueno': 275,\n",
       " 'suerte': 276,\n",
       " 'necesitamos': 277,\n",
       " 'estais': 278,\n",
       " 'haciendo': 279,\n",
       " 'reloj': 280,\n",
       " 'perdi': 281,\n",
       " 'hasta': 282,\n",
       " 'momento': 283,\n",
       " 'toma': 284,\n",
       " 'tres': 285,\n",
       " 'queremos': 286,\n",
       " 'sigue': 287,\n",
       " 'viene': 288,\n",
       " 'escuela': 289,\n",
       " 'llave': 290,\n",
       " 'culpa': 291,\n",
       " 'historia': 292,\n",
       " 'vete': 293,\n",
       " 'fuerte': 294,\n",
       " 'calor': 295,\n",
       " 'vas': 296,\n",
       " 'cafe': 297,\n",
       " 'gran': 298,\n",
       " 'temprano': 299,\n",
       " 'cerca': 300,\n",
       " 'cerveza': 301,\n",
       " 'llorar': 302,\n",
       " 'irme': 303,\n",
       " 'jugar': 304,\n",
       " 'perdio': 305,\n",
       " 'ido': 306,\n",
       " 'sola': 307,\n",
       " 'venir': 308,\n",
       " 'vivo': 309,\n",
       " 'di': 310,\n",
       " 'necesitas': 311,\n",
       " 'seas': 312,\n",
       " 'hijo': 313,\n",
       " 'media': 314,\n",
       " 'cuanto': 315,\n",
       " 'leer': 316,\n",
       " 'ingles': 317,\n",
       " 'semana': 318,\n",
       " 'mia': 319,\n",
       " 'trabaja': 320,\n",
       " 'cosas': 321,\n",
       " 'gusto': 322,\n",
       " 'pagar': 323,\n",
       " 'pueden': 324,\n",
       " 'tuve': 325,\n",
       " 'han': 326,\n",
       " 'gente': 327,\n",
       " 'manos': 328,\n",
       " 'libre': 329,\n",
       " 'salir': 330,\n",
       " 'esperar': 331,\n",
       " 'estupido': 332,\n",
       " 'leche': 333,\n",
       " 'cierto': 334,\n",
       " 'lista': 335,\n",
       " 'dificil': 336,\n",
       " 'muerto': 337,\n",
       " 'llama': 338,\n",
       " 'borracho': 339,\n",
       " 'vale': 340,\n",
       " 'bebe': 341,\n",
       " 'camino': 342,\n",
       " 'duro': 343,\n",
       " 'vos': 344,\n",
       " 'estaban': 345,\n",
       " 'zapatos': 346,\n",
       " 'sea': 347,\n",
       " 'llego': 348,\n",
       " 'primero': 349,\n",
       " 'hazlo': 350,\n",
       " 'trabajar': 351,\n",
       " 'quedate': 352,\n",
       " 'comiendo': 353,\n",
       " 'decir': 354,\n",
       " 'esos': 355,\n",
       " 'minuto': 356,\n",
       " 'bicicleta': 357,\n",
       " 'pasa': 358,\n",
       " 'lado': 359,\n",
       " 'quedo': 360,\n",
       " 'asi': 361,\n",
       " 'gatos': 362,\n",
       " 'o': 363,\n",
       " 'hermana': 364,\n",
       " 'familia': 365,\n",
       " 'respuesta': 366,\n",
       " 'ayer': 367,\n",
       " 'rico': 368,\n",
       " 'divertido': 369,\n",
       " 'extrano': 370,\n",
       " 'vuelve': 371,\n",
       " 'hacia': 372,\n",
       " 'persona': 373,\n",
       " 'llamo': 374,\n",
       " 'mala': 375,\n",
       " 'ninos': 376,\n",
       " 'sombrero': 377,\n",
       " 'saben': 378,\n",
       " 'hablando': 379,\n",
       " 'quieren': 380,\n",
       " 'ama': 381,\n",
       " 'ves': 382,\n",
       " 'cabeza': 383,\n",
       " 'debe': 384,\n",
       " 'volvio': 385,\n",
       " 'malo': 386,\n",
       " 'funciona': 387,\n",
       " 'aca': 388,\n",
       " 'da': 389,\n",
       " 'chico': 390,\n",
       " 'caja': 391,\n",
       " 'queda': 392,\n",
       " 'boca': 393,\n",
       " 'telefono': 394,\n",
       " 'vuelta': 395,\n",
       " 'paso': 396,\n",
       " 'cuenta': 397,\n",
       " 'felices': 398,\n",
       " 'empezo': 399,\n",
       " 'plan': 400,\n",
       " 'juego': 401,\n",
       " 'estabas': 402,\n",
       " 'comio': 403,\n",
       " 'esperando': 404,\n",
       " 'bajo': 405,\n",
       " 'estabamos': 406,\n",
       " 'vosotros': 407,\n",
       " 'abogado': 408,\n",
       " 'cara': 409,\n",
       " 'otro': 410,\n",
       " 'lleva': 411,\n",
       " 'mintiendo': 412,\n",
       " 'inteligente': 413,\n",
       " 'hiciste': 414,\n",
       " 'edad': 415,\n",
       " 'parar': 416,\n",
       " 'deberiamos': 417,\n",
       " 'verte': 418,\n",
       " 'tenis': 419,\n",
       " 'estuve': 420,\n",
       " 'importante': 421,\n",
       " 'esposa': 422,\n",
       " 'debes': 423,\n",
       " 'sal': 424,\n",
       " 'entiendo': 425,\n",
       " 'tome': 426,\n",
       " 'ocupada': 427,\n",
       " 'encontre': 428,\n",
       " 'amor': 429,\n",
       " 'encantan': 430,\n",
       " 'vuestro': 431,\n",
       " 'secreto': 432,\n",
       " 'suficiente': 433,\n",
       " 'palabra': 434,\n",
       " 'bailar': 435,\n",
       " 'sido': 436,\n",
       " 'manzana': 437,\n",
       " 'ni': 438,\n",
       " 'nuestra': 439,\n",
       " 'cierra': 440,\n",
       " 'venga': 441,\n",
       " 'cuidado': 442,\n",
       " 'come': 443,\n",
       " 'estare': 444,\n",
       " 'ciudad': 445,\n",
       " 'podes': 446,\n",
       " 'conoces': 447,\n",
       " 'lugar': 448,\n",
       " 'profesor': 449,\n",
       " 'habia': 450,\n",
       " 'ojala': 451,\n",
       " 'queres': 452,\n",
       " 'guerra': 453,\n",
       " 'aun': 454,\n",
       " 'camisa': 455,\n",
       " 'escucha': 456,\n",
       " 'gano': 457,\n",
       " 'acaso': 458,\n",
       " 'asiento': 459,\n",
       " 'dormido': 460,\n",
       " 'equivocado': 461,\n",
       " 'leyendo': 462,\n",
       " 'odia': 463,\n",
       " 'hermano': 464,\n",
       " 'afuera': 465,\n",
       " 'hijos': 466,\n",
       " 'toda': 467,\n",
       " 'sento': 468,\n",
       " 'despierto': 469,\n",
       " 'suyo': 470,\n",
       " 'salio': 471,\n",
       " 'carne': 472,\n",
       " 'ayudo': 473,\n",
       " 'levanto': 474,\n",
       " 'dice': 475,\n",
       " 'carta': 476,\n",
       " 'carro': 477,\n",
       " 'ambos': 478,\n",
       " 'pequeno': 479,\n",
       " 'bano': 480,\n",
       " 'cuarto': 481,\n",
       " 'llaves': 482,\n",
       " 'juntos': 483,\n",
       " 'estudiar': 484,\n",
       " 'parecia': 485,\n",
       " 'mesa': 486,\n",
       " 'parte': 487,\n",
       " 'correr': 488,\n",
       " 'deje': 489,\n",
       " 'hagas': 490,\n",
       " 'lejos': 491,\n",
       " 'termino': 492,\n",
       " 'tren': 493,\n",
       " 'importa': 494,\n",
       " 'dios': 495,\n",
       " 'hare': 496,\n",
       " 'grito': 497,\n",
       " 'ganar': 498,\n",
       " 'musica': 499,\n",
       " 'broma': 500,\n",
       " 'cancion': 501,\n",
       " 'digas': 502,\n",
       " 'tipo': 503,\n",
       " 'dolor': 504,\n",
       " 'sois': 505,\n",
       " 'conocen': 506,\n",
       " 'cuantos': 507,\n",
       " 'conoce': 508,\n",
       " 'tenes': 509,\n",
       " 'policia': 510,\n",
       " 'acaba': 511,\n",
       " 'seis': 512,\n",
       " 'suena': 513,\n",
       " 'sobre': 514,\n",
       " 'antes': 515,\n",
       " 'trabajando': 516,\n",
       " 'justo': 517,\n",
       " 'ello': 518,\n",
       " 'llame': 519,\n",
       " 'herido': 520,\n",
       " 'despues': 521,\n",
       " 'enojado': 522,\n",
       " 'tuyo': 523,\n",
       " 'dentro': 524,\n",
       " 'voz': 525,\n",
       " 'trampa': 526,\n",
       " 'tuvo': 527,\n",
       " 'equipo': 528,\n",
       " 'cocinar': 529,\n",
       " 'bolsa': 530,\n",
       " 'peligro': 531,\n",
       " 'chica': 532,\n",
       " 'canadiense': 533,\n",
       " 'amiga': 534,\n",
       " 'ropa': 535,\n",
       " 'serio': 536,\n",
       " 'gordo': 537,\n",
       " 'senti': 538,\n",
       " 'ten': 539,\n",
       " 'van': 540,\n",
       " 'caminar': 541,\n",
       " 'podeis': 542,\n",
       " 'teneis': 543,\n",
       " 'venido': 544,\n",
       " 'oido': 545,\n",
       " 'listos': 546,\n",
       " 'dias': 547,\n",
       " 'boligrafo': 548,\n",
       " 'reglas': 549,\n",
       " 'doctor': 550,\n",
       " 'llorando': 551,\n",
       " 'bromeando': 552,\n",
       " 'morir': 553,\n",
       " 'idiota': 554,\n",
       " 'error': 555,\n",
       " 'usar': 556,\n",
       " 'nina': 557,\n",
       " 'volver': 558,\n",
       " 'mucha': 559,\n",
       " 'padres': 560,\n",
       " 'largo': 561,\n",
       " 'despacio': 562,\n",
       " 'segundo': 563,\n",
       " 'olvide': 564,\n",
       " 'lloro': 565,\n",
       " 'echo': 566,\n",
       " 'paciente': 567,\n",
       " 'hombres': 568,\n",
       " 'amable': 569,\n",
       " 'sentia': 570,\n",
       " 'fin': 571,\n",
       " 'encontrar': 572,\n",
       " 'escucho': 573,\n",
       " 'pescado': 574,\n",
       " 'ingenuo': 575,\n",
       " 'casado': 576,\n",
       " 'aburrido': 577,\n",
       " 'saber': 578,\n",
       " 'alla': 579,\n",
       " 'quienes': 580,\n",
       " 'mujeres': 581,\n",
       " 'taxi': 582,\n",
       " 'tanto': 583,\n",
       " 'estudiando': 584,\n",
       " 'fumar': 585,\n",
       " 'dime': 586,\n",
       " 'autobus': 587,\n",
       " 'estudiante': 588,\n",
       " 'siguio': 589,\n",
       " 'deberias': 590,\n",
       " 'esas': 591,\n",
       " 'rompio': 592,\n",
       " 'pedi': 593,\n",
       " 'banco': 594,\n",
       " 'vaya': 595,\n",
       " 'perfecto': 596,\n",
       " 'toca': 597,\n",
       " 'pie': 598,\n",
       " 'genial': 599,\n",
       " 'cambio': 600,\n",
       " 'falta': 601,\n",
       " 'anda': 602,\n",
       " 'corriendo': 603,\n",
       " 'recuerdo': 604,\n",
       " 'dicho': 605,\n",
       " 'enfadado': 606,\n",
       " 'quieras': 607,\n",
       " 'roto': 608,\n",
       " 'manzanas': 609,\n",
       " 'sera': 610,\n",
       " 'ruido': 611,\n",
       " 'conducir': 612,\n",
       " 'japones': 613,\n",
       " 'verlo': 614,\n",
       " 'gustaria': 615,\n",
       " 'llamar': 616,\n",
       " 'compro': 617,\n",
       " 'sol': 618,\n",
       " 'seria': 619,\n",
       " 'tokio': 620,\n",
       " 'cosa': 621,\n",
       " 'camara': 622,\n",
       " 'manera': 623,\n",
       " 'mantente': 624,\n",
       " 'vista': 625,\n",
       " 'vayas': 626,\n",
       " 'entra': 627,\n",
       " 'prisa': 628,\n",
       " 'comi': 629,\n",
       " 'pago': 630,\n",
       " 'cansada': 631,\n",
       " 'caliente': 632,\n",
       " 'atras': 633,\n",
       " 'fueron': 634,\n",
       " 'contento': 635,\n",
       " 'llega': 636,\n",
       " 'dejar': 637,\n",
       " 'irte': 638,\n",
       " 'cocina': 639,\n",
       " 'ayudarte': 640,\n",
       " 'pregunto': 641,\n",
       " 'medico': 642,\n",
       " 'mirando': 643,\n",
       " 'brazo': 644,\n",
       " 'matar': 645,\n",
       " 'viste': 646,\n",
       " 'tener': 647,\n",
       " 'hermanos': 648,\n",
       " 'puesto': 649,\n",
       " 'adonde': 650,\n",
       " 'empezar': 651,\n",
       " 'ningun': 652,\n",
       " 'timido': 653,\n",
       " 'abre': 654,\n",
       " 'dejalo': 655,\n",
       " 'pan': 656,\n",
       " 'escribe': 657,\n",
       " 'normal': 658,\n",
       " 'correcto': 659,\n",
       " 'mama': 660,\n",
       " 'problemas': 661,\n",
       " 'sed': 662,\n",
       " 'posible': 663,\n",
       " 'pasado': 664,\n",
       " 'habeis': 665,\n",
       " 'perder': 666,\n",
       " 'volvere': 667,\n",
       " 'turno': 668,\n",
       " 'vayamos': 669,\n",
       " 'vere': 670,\n",
       " 'sintio': 671,\n",
       " 'paga': 672,\n",
       " 'vacia': 673,\n",
       " 'cena': 674,\n",
       " 'ganas': 675,\n",
       " 'lloviendo': 676,\n",
       " 'todas': 677,\n",
       " 'dano': 678,\n",
       " 'quisiera': 679,\n",
       " 'esperanza': 680,\n",
       " 'paris': 681,\n",
       " 'aquel': 682,\n",
       " 'cualquier': 683,\n",
       " 'dar': 684,\n",
       " 'solia': 685,\n",
       " 'papel': 686,\n",
       " 'adentro': 687,\n",
       " 'luego': 688,\n",
       " 'ire': 689,\n",
       " 'sabemos': 690,\n",
       " 'quede': 691,\n",
       " 'salvo': 692,\n",
       " 'enferma': 693,\n",
       " 'rojo': 694,\n",
       " 'baja': 695,\n",
       " 'coge': 696,\n",
       " 'tuya': 697,\n",
       " 'llegado': 698,\n",
       " 'empieza': 699,\n",
       " 'pregunta': 700,\n",
       " 'mentiroso': 701,\n",
       " 'blanco': 702,\n",
       " 'irse': 703,\n",
       " 'guapa': 704,\n",
       " 'huele': 705,\n",
       " 'bus': 706,\n",
       " 'nosotras': 707,\n",
       " 'noticias': 708,\n",
       " 'nieve': 709,\n",
       " 'pego': 710,\n",
       " 'rio': 711,\n",
       " 'valiente': 712,\n",
       " 'disparo': 713,\n",
       " 'tonto': 714,\n",
       " 'limitate': 715,\n",
       " 'corazon': 716,\n",
       " 'haces': 717,\n",
       " 'viven': 718,\n",
       " 'apenas': 719,\n",
       " 'fiesta': 720,\n",
       " 'intento': 721,\n",
       " 'agradable': 722,\n",
       " 'abajo': 723,\n",
       " 'adelante': 724,\n",
       " 'espere': 725,\n",
       " 'vuelto': 726,\n",
       " 'sonrio': 727,\n",
       " 'raro': 728,\n",
       " 'caso': 729,\n",
       " 'quedar': 730,\n",
       " 'detesto': 731,\n",
       " 'hielo': 732,\n",
       " 'hago': 733,\n",
       " 'canta': 734,\n",
       " 'hicimos': 735,\n",
       " 'haga': 736,\n",
       " 'conocemos': 737,\n",
       " 'comprar': 738,\n",
       " 'unos': 739,\n",
       " 'dulce': 740,\n",
       " 'engano': 741,\n",
       " 'jefe': 742,\n",
       " 'pude': 743,\n",
       " 'tomo': 744,\n",
       " 'llevo': 745,\n",
       " 'empleo': 746,\n",
       " 'toco': 747,\n",
       " 'luz': 748,\n",
       " 'arma': 749,\n",
       " 'caballo': 750,\n",
       " 'dejes': 751,\n",
       " 'pescar': 752,\n",
       " 'tio': 753,\n",
       " 'menudo': 754,\n",
       " 'muchos': 755,\n",
       " 'verano': 756,\n",
       " 'llegar': 757,\n",
       " 'haber': 758,\n",
       " 'dientes': 759,\n",
       " 'consejo': 760,\n",
       " 'llover': 761,\n",
       " 'pidio': 762,\n",
       " 'foto': 763,\n",
       " 'torta': 764,\n",
       " 'nuestros': 765,\n",
       " 'hola': 766,\n",
       " 'vemos': 767,\n",
       " 'ponte': 768,\n",
       " 'intenta': 769,\n",
       " 'buenas': 770,\n",
       " 'terminado': 771,\n",
       " 'pasar': 772,\n",
       " 'sientate': 773,\n",
       " 'venid': 774,\n",
       " 'lee': 775,\n",
       " 'mando': 776,\n",
       " 'gratis': 777,\n",
       " 'hicieron': 778,\n",
       " 'miro': 779,\n",
       " 'debemos': 780,\n",
       " 'pero': 781,\n",
       " 'preparado': 782,\n",
       " 'nervioso': 783,\n",
       " 'vivir': 784,\n",
       " 'piensa': 785,\n",
       " 'colegio': 786,\n",
       " 'corto': 787,\n",
       " 'entro': 788,\n",
       " 'papa': 789,\n",
       " 'pajaro': 790,\n",
       " 'beso': 791,\n",
       " 'cuerda': 792,\n",
       " 'futbol': 793,\n",
       " 'caballos': 794,\n",
       " 'prefiero': 795,\n",
       " 'viendo': 796,\n",
       " 'escuchando': 797,\n",
       " 'japon': 798,\n",
       " 'eran': 799,\n",
       " 'adora': 800,\n",
       " 'escribio': 801,\n",
       " 'muerte': 802,\n",
       " 'enemigo': 803,\n",
       " 'confiar': 804,\n",
       " 'ventana': 805,\n",
       " 'fuego': 806,\n",
       " 'levanta': 807,\n",
       " 'preguntale': 808,\n",
       " 'hable': 809,\n",
       " 'lleno': 810,\n",
       " 'pajaros': 811,\n",
       " 'irnos': 812,\n",
       " 'adoro': 813,\n",
       " 'muriendo': 814,\n",
       " 'diez': 815,\n",
       " 'mire': 816,\n",
       " 'cualquiera': 817,\n",
       " 'agrada': 818,\n",
       " 'nueva': 819,\n",
       " 'contacto': 820,\n",
       " 'aire': 821,\n",
       " 'sopa': 822,\n",
       " 'atrapado': 823,\n",
       " 'cerro': 824,\n",
       " 'mayor': 825,\n",
       " 'pena': 826,\n",
       " 'paciencia': 827,\n",
       " 'ayudarme': 828,\n",
       " 'gustaba': 829,\n",
       " 'negro': 830,\n",
       " 'alta': 831,\n",
       " 'algunos': 832,\n",
       " 'peso': 833,\n",
       " 'dale': 834,\n",
       " 'nariz': 835,\n",
       " 'pienso': 836,\n",
       " 'respeto': 837,\n",
       " 'dan': 838,\n",
       " 'toques': 839,\n",
       " 'taza': 840,\n",
       " 'camion': 841,\n",
       " 'punto': 842,\n",
       " 'almuerzo': 843,\n",
       " 'dedo': 844,\n",
       " 'lapiz': 845,\n",
       " 'totalmente': 846,\n",
       " 'acerca': 847,\n",
       " 'corre': 848,\n",
       " 'quieto': 849,\n",
       " 'calvo': 850,\n",
       " 'debil': 851,\n",
       " 'cayo': 852,\n",
       " 'veia': 853,\n",
       " 'silencio': 854,\n",
       " 'arriba': 855,\n",
       " 'entonces': 856,\n",
       " 'cantando': 857,\n",
       " 'heroe': 858,\n",
       " 'soltero': 859,\n",
       " 'real': 860,\n",
       " 'ojo': 861,\n",
       " 'intentarlo': 862,\n",
       " 'verme': 863,\n",
       " 'vengo': 864,\n",
       " 'chicos': 865,\n",
       " 'azul': 866,\n",
       " 'gustas': 867,\n",
       " 'alguna': 868,\n",
       " 'necesitaba': 869,\n",
       " 'veces': 870,\n",
       " 'durmiendo': 871,\n",
       " 'monton': 872,\n",
       " 'grandes': 873,\n",
       " 'mios': 874,\n",
       " 'tarta': 875,\n",
       " 'descansar': 876,\n",
       " 'atencion': 877,\n",
       " 'claro': 878,\n",
       " 'robo': 879,\n",
       " 'encontrado': 880,\n",
       " 'escribir': 881,\n",
       " 'ley': 882,\n",
       " 'vendra': 883,\n",
       " 'treinta': 884,\n",
       " 'simplemente': 885,\n",
       " 'cinco': 886,\n",
       " 'gafas': 887,\n",
       " 'tele': 888,\n",
       " 'abierta': 889,\n",
       " 'peligroso': 890,\n",
       " 'mensaje': 891,\n",
       " 'cartas': 892,\n",
       " 'orgulloso': 893,\n",
       " 'abrir': 894,\n",
       " 'misma': 895,\n",
       " 'alegro': 896,\n",
       " 'continua': 897,\n",
       " 'ganado': 898,\n",
       " 'corrio': 899,\n",
       " 'ninguna': 900,\n",
       " 'calma': 901,\n",
       " 'ayudame': 902,\n",
       " 'mintio': 903,\n",
       " 'volar': 904,\n",
       " 'oscuro': 905,\n",
       " 'vimos': 906,\n",
       " 'hables': 907,\n",
       " 'asustado': 908,\n",
       " 'loca': 909,\n",
       " 'termina': 910,\n",
       " 'golf': 911,\n",
       " 'dudas': 912,\n",
       " 'confundido': 913,\n",
       " 'pierna': 914,\n",
       " 'abra': 915,\n",
       " 'necesitan': 916,\n",
       " 'gracioso': 917,\n",
       " 'vine': 918,\n",
       " 'primavera': 919,\n",
       " 'detras': 920,\n",
       " 'peor': 921,\n",
       " 'regalo': 922,\n",
       " 'espalda': 923,\n",
       " 'simple': 924,\n",
       " 'izquierda': 925,\n",
       " 'fuimos': 926,\n",
       " 'cuchillo': 927,\n",
       " 'traeme': 928,\n",
       " 'cambiado': 929,\n",
       " 'decision': 930,\n",
       " 'corbata': 931,\n",
       " 'crees': 932,\n",
       " 'abrio': 933,\n",
       " 'piano': 934,\n",
       " 'pasando': 935,\n",
       " 'paraguas': 936,\n",
       " 'piernas': 937,\n",
       " 'viajar': 938,\n",
       " 'completamente': 939,\n",
       " 'pelicula': 940,\n",
       " 'larga': 941,\n",
       " 'podrias': 942,\n",
       " 'creer': 943,\n",
       " 'caro': 944,\n",
       " 'abrigo': 945,\n",
       " 'hablas': 946,\n",
       " 'breve': 947,\n",
       " 'uso': 948,\n",
       " 'pagare': 949,\n",
       " 'estupendo': 950,\n",
       " 'toalla': 951,\n",
       " 'golpeo': 952,\n",
       " 'camina': 953,\n",
       " 'cruel': 954,\n",
       " 'mordio': 955,\n",
       " 'ocupados': 956,\n",
       " 'muneca': 957,\n",
       " 'deseo': 958,\n",
       " 'hermosa': 959,\n",
       " 'celoso': 960,\n",
       " 'saberlo': 961,\n",
       " 'canto': 962,\n",
       " 'bienvenido': 963,\n",
       " 'estudio': 964,\n",
       " 'culpable': 965,\n",
       " 'tenido': 966,\n",
       " 'bolso': 967,\n",
       " 'avion': 968,\n",
       " 'hambriento': 969,\n",
       " 'siente': 970,\n",
       " 'paz': 971,\n",
       " 'numero': 972,\n",
       " 'unas': 973,\n",
       " 'pelota': 974,\n",
       " 'riendo': 975,\n",
       " 'estara': 976,\n",
       " 'muertos': 977,\n",
       " 'trata': 978,\n",
       " 'viaje': 979,\n",
       " 'preocupado': 980,\n",
       " 'radio': 981,\n",
       " 'oficina': 982,\n",
       " 'lago': 983,\n",
       " 'entiende': 984,\n",
       " 'vives': 985,\n",
       " 'nacio': 986,\n",
       " 'siendo': 987,\n",
       " 'oportunidad': 988,\n",
       " 'escuche': 989,\n",
       " 'llamame': 990,\n",
       " 'entre': 991,\n",
       " 'gorda': 992,\n",
       " 'prueba': 993,\n",
       " 'profundo': 994,\n",
       " 'perfectamente': 995,\n",
       " 'llena': 996,\n",
       " 'pobre': 997,\n",
       " 'gane': 998,\n",
       " 'confia': 999,\n",
       " 'vosotras': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_lang.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4QILQkOs3jFG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000 24000 6000 6000\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lJPmLZGMeD5q"
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VXukARTDd7MT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "58 ----> ahora\n",
      "16 ----> esta\n",
      "10 ----> a\n",
      "692 ----> salvo\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "6 ----> you\n",
      "23 ----> re\n",
      "375 ----> safe\n",
      "58 ----> now\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgCLkfv5uO3d"
   },
   "source": [
    "### Create a tf.data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TqHsArVZ3jFS"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qc6-NK1GtWQt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 16]), TensorShape([64, 11]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TNfHIF71ulLu"
   },
   "source": [
    "## Write the encoder and decoder model\n",
    "\n",
    "Implement an encoder-decoder model with attention which you can read about in the TensorFlow [Neural Machine Translation (seq2seq) tutorial](https://github.com/tensorflow/nmt). This example uses a more recent set of APIs. This notebook implements the [attention equations](https://github.com/tensorflow/nmt#background-on-the-attention-mechanism) from the seq2seq tutorial. The following diagram shows that each input words is assigned a weight by the attention mechanism which is then used by the decoder to predict the next word in the sentence. The below picture and formulas are an example of attention mechanism from [Luong's paper](https://arxiv.org/abs/1508.04025v5). \n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\" width=\"500\" alt=\"attention mechanism\">\n",
    "\n",
    "The input is put through an encoder model which gives us the encoder output of shape *(batch_size, max_length, hidden_size)* and the encoder hidden state of shape *(batch_size, hidden_size)*.\n",
    "\n",
    "Here are the equations that are implemented:\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">\n",
    "\n",
    "This tutorial uses [Bahdanau attention](https://arxiv.org/pdf/1409.0473.pdf) for the encoder. Let's decide on notation before writing the simplified form:\n",
    "\n",
    "* FC = Fully connected (dense) layer\n",
    "* EO = Encoder output\n",
    "* H = hidden state\n",
    "* X = input to the decoder\n",
    "\n",
    "And the pseudo-code:\n",
    "\n",
    "* `score = FC(tanh(FC(EO) + FC(H)))`\n",
    "* `attention weights = softmax(score, axis = 1)`. Softmax by default is applied on the last axis but here we want to apply it on the *1st axis*, since the shape of score is *(batch_size, max_length, hidden_size)*. `Max_length` is the length of our input. Since we are trying to assign a weight to each input, softmax should be applied on that axis.\n",
    "* `context vector = sum(attention weights * EO, axis = 1)`. Same reason as above for choosing axis as 1.\n",
    "* `embedding output` = The input to the decoder X is passed through an embedding layer.\n",
    "* `merged vector = concat(embedding output, context vector)`\n",
    "* This merged vector is then given to the GRU\n",
    "\n",
    "The shapes of all the vectors at each step have been specified in the comments in the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nZ2rI24i3jFg"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60gSVh05Jl6l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "umohpBN2OM94"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 1024]), TensorShape([64, 16, 1024]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_hidden.shape, sample_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k534zTHiDjQU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 1024]), TensorShape([64, 16, 1]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_result.shape, attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJ_B3mhW3jFk"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.uniform((64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P5UY8wko3jFp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ch_71VbIRfK"
   },
   "source": [
    "## Define the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WmTHr5iV3jFr"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DMVWzzsfNl4e"
   },
   "source": [
    "## Checkpoints (Object-based saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zj8bXQTgNwrF"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hpObfY22IddU"
   },
   "source": [
    "## Training\n",
    "\n",
    "1. Pass the *input* through the *encoder* which return *encoder output* and the *encoder hidden state*.\n",
    "2. The encoder output, encoder hidden state and the decoder input (which is the *start token*) is passed to the decoder.\n",
    "3. The decoder returns the *predictions* and the *decoder hidden state*.\n",
    "4. The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
    "5. Use *teacher forcing* to decide the next input to the decoder.\n",
    "6. *Teacher forcing* is the technique where the *target word* is passed as the *next input* to the decoder.\n",
    "7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sC9ArXSsVfqn"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddefjBMa3jF0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.7230\n",
      "Epoch 1 Batch 100 Loss 2.2490\n",
      "Epoch 1 Batch 200 Loss 1.9105\n",
      "Epoch 1 Batch 300 Loss 1.6870\n",
      "Epoch 1 Loss 2.0278\n",
      "Time taken for 1 epoch 625.8410859107971 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.6573\n",
      "Epoch 2 Batch 100 Loss 1.4563\n",
      "Epoch 2 Batch 200 Loss 1.2554\n",
      "Epoch 2 Batch 300 Loss 1.1420\n",
      "Epoch 2 Loss 1.3546\n",
      "Time taken for 1 epoch 586.8508200645447 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.0742\n",
      "Epoch 3 Batch 100 Loss 0.9834\n",
      "Epoch 3 Batch 200 Loss 0.9895\n",
      "Epoch 3 Batch 300 Loss 0.9342\n",
      "Epoch 3 Loss 0.9249\n",
      "Time taken for 1 epoch 570.790666103363 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.6307\n",
      "Epoch 4 Batch 100 Loss 0.6212\n",
      "Epoch 4 Batch 200 Loss 0.5851\n",
      "Epoch 4 Batch 300 Loss 0.5899\n",
      "Epoch 4 Loss 0.6138\n",
      "Time taken for 1 epoch 579.0654871463776 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.3874\n",
      "Epoch 5 Batch 100 Loss 0.3860\n",
      "Epoch 5 Batch 200 Loss 0.4181\n",
      "Epoch 5 Batch 300 Loss 0.4917\n",
      "Epoch 5 Loss 0.4157\n",
      "Time taken for 1 epoch 617.9903140068054 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.2222\n",
      "Epoch 6 Batch 100 Loss 0.2582\n",
      "Epoch 6 Batch 200 Loss 0.3448\n",
      "Epoch 6 Batch 300 Loss 0.3264\n",
      "Epoch 6 Loss 0.2889\n",
      "Time taken for 1 epoch 591.0321080684662 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1742\n",
      "Epoch 7 Batch 100 Loss 0.1761\n",
      "Epoch 7 Batch 200 Loss 0.2160\n",
      "Epoch 7 Batch 300 Loss 0.1933\n",
      "Epoch 7 Loss 0.2080\n",
      "Time taken for 1 epoch 592.3718559741974 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1484\n",
      "Epoch 8 Batch 100 Loss 0.1880\n",
      "Epoch 8 Batch 200 Loss 0.1678\n",
      "Epoch 8 Batch 300 Loss 0.1569\n",
      "Epoch 8 Loss 0.1566\n",
      "Time taken for 1 epoch 596.5373878479004 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0923\n",
      "Epoch 9 Batch 100 Loss 0.1072\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mU3Ce8M6I3rz"
   },
   "source": [
    "## Translate\n",
    "\n",
    "* The evaluate function is similar to the training loop, except we don't use *teacher forcing* here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
    "* Stop predicting when the model predicts the *end token*.\n",
    "* And store the *attention weights for every time step*.\n",
    "\n",
    "Note: The encoder output is calculated only once for one input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EbQpyYs13jF_"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s5hQWlbN3jGF"
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sl9zUHzg3jGI"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n250XbnjOaqP"
   },
   "source": [
    "## Restore the latest checkpoint and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UJpT9D5_OgP6"
   },
   "outputs": [],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WrAM0FDomq3E"
   },
   "outputs": [],
   "source": [
    "translate(u'hace mucho frio aqui.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zSx2iM36EZQZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> esta es mi vida . <end>\n",
      "Predicted translation: this is my life . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAJwCAYAAAAjo60MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3debSlB1nn+9+TgcQQIjIPMiniwHhjySDdGMErisptaVpbCQTwJi6HNl5avc3qS0vTIoNBG0VpAkrC0Armto2IoChwoRmkgUZkUEBmIUCQISGQhOS5f+xdcjipCnVOKvU+++TzWeus2ufd++x6zruq6nzrHau7AwDA8o5aegAAAFaEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMJsoKr6pqp6RVXdeelZAIAjR5jNdFqSU5I8cuE5AIAjqNzEfJaqqiQfSPLyJD+U5BbdffmiQwEAR4QtZvOckuR6SX4uyZeSPGDRaQCAI0aYzXNakvO6++Ikf7D+HAC4FrArc5Cqum6SjyX5ge5+TVXdLcnrk9y8uz+z7HQAwDXNFrNZ/mWSC7r7NUnS3W9N8p4k/3rRqQBgg1TVdavqYVX1tUvPslPCbJaHJnnetmXPS/LwIz8KAGysH0ny7Kx+rm4UuzKHqKpbJXl/km/t7vdsWf71WZ2l+W3d/e6FxgOAjVFVr0xy0yQXd/e+pefZCWEGAOwZVXXbJO9Ocvckb0hycne/c8mZdsKuzEGq6tbr65gd8LkjPQ8AbKCHJnnN+jjtP82GXd1AmM3y/iQ33r6wqm64fg4AuGoPS/Lc9ePnJ3nIwTZ6TCTMZqkkB9q3fGKSLx7hWQBgo1TVdya5eZLz1otenOSEJN+z2FA7dMzSA5BU1W+uH3aSJ1TVxVuePjqr/eRvPeKDAcBmOS3Ji7r7oiTp7kur6oVZXd3g5UsOdqiE2Qx3Xv9aSb41yaVbnrs0yVuSnHWkhwKATVFVx2V1mYwf2/bU85L8WVWduD/YJnNW5hDr/d8vTPLI7r5w6XkAYJNU1Y2yur/087r7im3PnZrkL7r7/EWG2wFhNkRVHZ3VcWR33aTTegGAw8fB/0N09+VJPpjkOkvPAgAswxazQarqtKz2jZ/a3RcsPQ8ATFdV78+Br2hwJd39DdfwOFebg/9n+YUkt0vyD1X1kSSf3/pkd99lkakAYK6nbXl8YpJHJXljktevl90rq6sbPOUIz7UrwmyW8776SwCA/br7n4Krqs5J8qTu/tWtr6mqRye54xEebVfsygQA9oSq+lxW98Z877blt0/ylu4+aZnJDp2D/wGAveLzSU45wPJTklx8gOXj2JU5SFVdJ8m/z+oEgFsnOXbr89199BJzAcCG+I0kv11V+5K8Yb3snlndEeCxSw21E8Jslv+U5EeTPCGrP1y/mOS2Sf51kscsNxYAzNfdT66qDyQ5M6u7ACTJu5Kc1t0vXGywHXCM2SDrU35/qrtfVlUXJrlbd/99Vf1Ukvt194MXHnGkqnpEvryV8SuuA7cJp0bDXldVX5fk+3Pgv6OPW2QoGMoWs1lummT/Vf8vSnL99eOXJXnSIhMNV1W/mOTRSZ6R5D5JfifJ7deP3V8UFlZV90zykiSXJLlxkn9IcvP15x9IIsy4RlTV9bPtWPru/seFxjlkDv6f5UNJbrF+/N4k918/vleSLywy0XynJzmjux+d5LIkT+vuB2Z1vZrbLDoZkCS/luT5SW6Z1W3n7pvVlrM3xX84Ocyq6jZV9dKq+kKSTyX55PrjgvWv49liNssfJblfVgcsPjXJ71fV6Vn9g/ZrSw422NdndSHBZBWv+0+F/v318tOXGAr4J3dJ8hPd3VV1eZLjuvt9VfV/J/mvWUUbHC7Pzmpv008k+WgO8Y4AkwizQdZbffY/Pq+qPpzk3kne3d1/stxko52f5EZZbW38YFZbF9+a1e7MjfsLCXvQpVsefzyrLdnvyupwjVsc8Ctg9+6e5J7d/falB9ktYTZIVd0nyeu6+0tJ0t1/leSvquqYqrpPd7962QlHekWSByZ5S5LfTfIbVfUjSU5OshFn4MAe95Yk35Hk3UleleRXquqmSU5N8rYF52Jven+S45Ye4upwVuYg6838N+/uT2xbfsMkn3AdsyurqqOSHLU/ZqvqR7PeypjkGd192ZLzwbXd+npS1+vuV1bVjZM8J1/+O/qI7v6bRQdkT6mq+yb5d0l+evvV/zeFMBukqq5IctPu/uS25XdI8qZNuJXEkVZVt07y4d72B7mqKsmtuvtDy0wGwJG2vtTUcUmOzurM3y9tfX4Tfo7alTlAVf3x+mEneV5VXbLl6aOT3CnJ6474YJvh/Vmdev+JbctvsH7OVkaAa4+fXXqAq0uYzfCp9a+V5NP5yktjXJrkfyR55pEeakNUDnyQ/4lZnZoPHGHri2Uf0u4YF4HmcOruc5ee4eoSZgN09yOSZH0bibO6+/PLTjRfVf3m+mEneUJVbb057dFZnZnz1iM+GJAkT9vy+MQkj8rq8jWvXy+7V1Z/R59yhOfiWmB9cslDk3xjksd09wVVde8kH+3u9y873VfnGLNB1geyp7uvWH9+syQ/mOSd3W1X5hZV9cr1w+/K6h/7rafkX5rVFcXP6u73HOHRgC2q6pysLvnzq9uWPzrJHbv71EUGY0+qqm9P8pdZHcpyxyTfsr5u3mOT3KG7f3zJ+Q6FMBukql6a5GXd/dSqOjHJ3ya5blb/4/yJ7n7OogMOVFXPTnJmd39u6VmAK6uqzyU5efsZclV1+yRv2YSDsdkc6/+0v7q7f3l9IsBd12F2ryR/0N3j7whjV+Ys+5L80vrxg5J8LsntkjwkyS9kdZo5W+zfDbxfVX1NVqfiv6e7P7jMVJvHeju4qnpQkhd392XrxwfV3f/tCI21ST6f5JSsbjO31SlJLt7+Yriavj2rq/5v97Gs7kc9njCb5cQkn1k//t4kf7T+YfCKJL+93FhzrXeTvLG7f6eqrpPVcSx3THJpVf1wd7900QGHst525LwkN8vqzN/zruJ1HWcBH8hvJPnt9fXM3rBeds8kpyV57FJDsWd9IcnXHWD5t+TKZ++P5Cbms3woyb2r6rpZ3cD85evlN4j/WR7M/fPlf+wfmOR6Wf0QfWz8o39VrLdD1N1H7b/o8/rxwT5E2QF095OzOhD7zkl+ff1x5ySndbebmHO4vSjJL1fV/qv/d1XdNsmTkvy/Sw21E44xG6SqfjKrs5kuyuq+jyd39xVV9XNJ/kV333fRAQeqqi8muX13f6SqnpXks939b9d/Ef+mu6+36IBDWW+7tz7j695JbpKv/M9td/fTl5kKSJKqOinJnya5S1bHaJ+f1S7M1yX5/k246oFdmYN09zOq6k1Jbp3k5fvPzkzy90kes9xko52f5E5V9bGstgKdsV5+YhK3Yzo4620XqurUJM/Kl685uPV/tp1EmMGC1ieC/bP1rZlOzuo/T2/p7r9YdrJDJ8yGqKqvTXKX7n5Nkjdve/ozSd555KfaCL+X5AVJPprk8qxOk06Se2R1VisHZr3tzuOTPDnJ4/bfn5UrW5+J+Q3r60ddmKu42KyzMjlctv4c7e5XJHnFlufundWlpz692ICHSJjNcUWSl1bV/bv7tfsXVtVds/rDdcvFJhusux9XVW9PcpskL+zu/dcz+1JWxxRwANbbrp2U5BxR9lX9myQXrh9v/C1y2Bh74ueog/+H6O4Lszpo8WHbnnpokj/r7guO/FQb4wtJvifJy6vqVutl18nqWD0Oznrbuecn+YGlh5iuu8/t7v33/P3hrP5M/f56+Vd8LDgme8xe+TkqzGZ5TpJ/tb58wf47Afx4knOWHGqyqnpIkhcmeXdW13w7dv3UUfnyNeHYxnrbtUcl+f6q+u9V9Z+q6j9s/Vh6uKEuTnJuko9X1bOq6ruWHog9beN/jgqzWV6e1VaMH1x/fr+stmC8eLGJ5vulJKd39/+V1W64/d6Q5G7LjLQRrLfd+ckk35fkO7PaEvSvtnw8eMG5xlrfAuemWe3evEVWW2g/WFVPrKo7LTsde9DG/xwVZoOsz8J8Xr68GfahSV7Q3c6SO7hvypdvjLzVRVkdD8SBWW+785gk/7a7b9Ldd+ruO2/5uMvSw03V3Z/v7ud19wOyOs7n17L6wfnWZSdjr9kLP0cd/D/Pc5K8uapundX/yO+38DzTfTTJHbK67ttW98nqMiMcmPW2O0cn+eOlh9hUVXV8kvtmdYmWOyT58LITsUdt9M9RW8yG6e53JHl7VgcZf6S737jwSNOdneQ316dCJ8mtquq0rC5p4JpSB2e97c6zs7p3LYeoVr63qs5N8vGs/nx9NMn9uvt2y07HXrTpP0dtMZvpOUn+c5J/v/Qg03X3k9fXrnl5kuOTvDLJJUnO6m73Fz0I623XTkjyf1bV/ZO8LdsuxtvdP7fIVLN9LKvd4y9N8vAkL9lyeRZ2oareleSbutvP8IPb2J+jbsk0UFXdIKsDZZ/R3ecvPc8mqKoTknxbVluB39ndLvlwCKy3namqV17F0+22aVdWVacn+cPu/szSs+wVVfWzSW7Y3f9x6Vmm2uSfo8IMAGAIx5gBAAwhzAAAhhBmg1XVGUvPsImst52zznbHetsd623nrLPd2cT1Jsxm27g/UENYbztnne2O9bY71tvOWWe7s3HrTZgBAAxxrT8r8zp1XB+f6y49xgFdlktybI5beoyNY73tnHW2O9bb7lhvOzd5ndVRc7fxXNpfzHXq+KXHOKDPXfGpC7r7xtuXX+svTnd8rpt71EbdrQEAxjjqhJkbN6b784vO3X5LvCR2ZQIAjCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhiZJhV1SlV1VV1o6vzGgCATTIizKrqVVX1tB1+2euS3DzJp66BkQAAjrhjlh5gt7r70iTnLz0HAMDhsvgWs6o6J8l3JfmZ9a7JTnLb9dN3raq/qqqLq+pNVXXylq/7il2ZVfW1VfXcqvpEVX2xqt5XVT9/pL8fAIDdWjzMkpyZ5PVJnp3VrsmbJ/nw+rknJPl3SU7Oapfl86uqDvI+v5Lkzkl+MMk3J3lkkn+45sYGADi8Ft+V2d2frapLk1zc3ecnSVV9y/rpx3T3K9fLHpfkfyS5ZZKPHOCtbpPkLd39xvXnHzzY71lVZyQ5I0mOzwmH5fsAALi6Jmwxuypv2/L4o+tfb3KQ1z49yY9W1V9X1VlV9V0He9PuPru793X3vmNz3OGaFQDgapkeZpdtedzrXw84c3e/NKutZmcluVGSl1TVs6/Z8QAADp8pYXZpkqOv7pt09wXd/dzufniSn0hyWlXZJAYAbITFjzFb+0CSu1fVbZNclF0E4/oYtLckeUdW39eDkryvuy85bFMCAFyDpmwxOyurrWbvTPLJJLfexXtckuTxSf46yWuTXC/JDx2uAQEArmnV3V/9VXvYSXWDvkfdb+kxAGAjHXXd6y49wkb684vOfXN379u+fMoWMwCAaz1hBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIY5ZeoCl1bHH5pib3mLpMTbOBx5226VH2Djf+H3vW3qEjXT5j/bSI2ykKz7z2aVH2DhXXHrZ0iNspCs+//mlR9hTbDEDABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhio8Osqs6pqj9Zeg4AgMPhmKUHuJrOTFJLDwEAcDhsdJh192eXngEA4HDZM7syq+o+VfWGqrqoqj5bVW+sqjstPSMAwKHa6C1m+1XVMUlelOR3kzwkybFJTk5y+ZJzAQDsxJ4IsyQnJbl+khd399+vl/3twV5cVWckOSNJjj/6etf8dAAAh2Cjd2Xu193/mOScJH9WVS+pqkdV1a2v4vVnd/e+7t53naO+5ojNCQBwVfZEmCVJdz8iyT2SvDrJA5P8XVXdf9mpAAAO3Z4JsyTp7r/u7id19ylJXpXktGUnAgA4dHsizKrqdlX1xKr6zqq6TVV9d5K7JHnn0rMBAByqvXLw/8VJ7pDkD5PcKMnHkzw/yZOWHAoAYCc2Osy6++FbPn3QUnMAABwOe2JXJgDAXiDMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwxDFLD7C0vuyyfOljH196jI3z9U/82NIjbJzLn3fLpUfYSKe/5lVLj7CRnvjYU5ceYePc4M/es/QIG+nyCz619Ah7ii1mAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMMS4MKuqV1XV06vqKVX1j1X1yao6s6qOq6rfrqrPVNWHquqh69e/oqqetu09Tqqqi6vqQct8FwAAOzcuzNYekuTCJPdI8sQk/znJf0/y7iT7kpyb5FlVdfMkz0zy41V13Jav/7EkFyV58ZEcGgDg6pgaZu/o7sd293uS/HqSC5Jc1t1P7e73Jnlckkpy7yT/LckVSX54y9c/MslzuvuyA715VZ1RVW+qqjddlkuu0W8EAOBQTQ2zt+1/0N2d5BNJ/mbLssuSfDrJTbr7kiTPzSrGUlV3THL3JL97sDfv7rO7e1937zs2xx3sZQAAR9QxSw9wENu3dPVBlu0Py2cleVtV3TqrQHt9d7/rmh0RAODwmrrFbEe6+x1J/irJ6UlOTfJ7y04EALBzU7eY7cYzk/yXrLasvWDhWQAAdmxPbDFbe0GSS5O8sLsvXHoYAICdGrfFrLtPOcCyOx1g2c22Lbp+kq/JVRz0DwAw2bgw26mqOjbJDZP8apL/1d2vXXgkAIBd2Qu7Mu+d5GNJvjOrg/8BADbSxm8x6+5XZXWxWQCAjbYXtpgBAOwJwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABjimKUHGOGKy5eegGuBL334I0uPsJGe+b/fd+kRNtJTXvE7S4+wcX7+Oj+z9Agb6QbnvnHpETbTQdLDFjMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAECPDrKrOqao/2f54/flRVfWMqvpUVXVVnbLYoAAAh9ExSw9wCM5MUls+f0CSRyQ5Jcn7kvzjAjMBABx248Osuz+7bdHtk3ysu1+3xDwAANeUkbsyt9q+WzPJbyS59Xo35gfWy6uqfqmq/r6qvlBVf1NVpy43NQDAzo3fYrbNmUk+mOSRSb4jyeXr5b+S5MFJfibJ3yW5V5JnVtWnu/slSwwKALBTGxVm3f3ZqrowyeXdfX6SVNV1kzwqyfd292vWL31/Vd09q1C7UphV1RlJzkiS43PCEZkdAOCr2agwO4hvS3J8kpdVVW9ZfmySDxzoC7r77CRnJ8lJdYM+0GsAAI60vRBm+4+T+6EkH9r23GVHeBYAgF3bC2H2ziSXJLlNd79i6WEAAHZr48Osuy+sqrOSnFVVleTVSU5Mcs8kV6x3WwIAjLfxYbb2mCQfT/ILSZ6e5HNJ3prkyUsOBQCwEyPDrLsffqDH68/PSnLWtmWd5LfWHwAAG2n8BWYBAK4thBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIY4ZukBAK7Klz7woaVH2Ej/z0//5NIjbJz/+XtPX3qEjfQDr/o/lh5hM73vwIttMQMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDHLD3AEqrqjCRnJMnxOWHhaQAAVq6VW8y6++zu3tfd+47NcUuPAwCQ5FoaZgAAEwkzAIAh9myYVdXPVtXfLj0HAMCh2rNhluRGSb556SEAAA7Vng2z7n5sd9fScwAAHKo9G2YAAJtGmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYIhjlh4AgMPv+Fe/Y+kRNs4df+unlx5hI/30S1689Agb6WXfeuDltpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhtiYMKuqX6iqDyw9BwDANWVjwgwAYK87LGFWVSdV1fUPx3vt4Pe8cVUdfyR/TwCAa9Kuw6yqjq6q+1fVf01yfpK7rpd/bVWdXVWfqKoLq+r/q6p9W77u4VV1UVXdr6reXlWfr6pXVtXttr3/L1XV+evXPifJidtGeECS89e/1713+30AAEyx4zCrqjtW1ZOTfDjJC5J8Psn3JXl1VVWSlyS5ZZIfTPK/JXl1kldU1c23vM1xSR6d5JFJ7pXk+kn+y5bf40eS/EqSX05ycpK/S/KobaM8P8mPJ7lekpdX1Xur6j9sDzwAgE1xSGFWVTesqp+rqjcn+V9JviXJmUlu1t2nd/eru7uTfHeSuyV5cHe/sbvf292PSfK+JA/d8pbHJPmZ9WveluSsJKeswy5Jfj7Jud39jO5+d3c/Pskbt87U3V/q7j/t7h9LcrMkv7r+/d9TVa+qqkdW1fatbPu/nzOq6k1V9abLcsmhrAIAgGvcoW4x+zdJnprki0nu0N0P7O4/7O4vbnvdtyc5Ickn17sgL6qqi5LcKck3bnndJd39d1s+/2iS6yT5uvXn35rk9dvee/vn/6S7P9fdv9fd353kO5LcNMnvJnnwQV5/dnfv6+59x+a4q/i2AQCOnGMO8XVnJ7ksycOSvL2q/ijJc5P8ZXdfvuV1RyX5eJJ/foD3+NyWx1/a9lxv+fodq6rjstp1empWx569I6utbi/azfsBACzhkEKouz/a3Y/v7m9O8j1JLkryB0k+UlVPqaq7rV/6lqy2Vl2x3o259eMTO5jrXUnuuW3ZV3xeK/+sqp6R1ckHv5XkvUm+vbtP7u6ndvend/B7AgAsasdbqLr7Dd39U0luntUuzjsk+Z9V9c+T/EWS1yZ5UVV9f1XdrqruVVX/cf38oXpqktOq6vSq+qaqenSSe2x7zalJ/jzJSUl+LMmtuvsXu/vtO/2eAAAmONRdmVfS3ZckOS/JeVV1kySXd3dX1QOyOqPymUluktWuzdcmec4O3vsFVfUNSR6f1TFrf5zk15M8fMvL/jKrkw8+d+V3AADYPLsOs6227qbs7guzOmPzzIO89pwk52xb9qoktW3ZE5I8YduXP3bL8x/d/cQAAPO4JRMAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQ26CnCsAAAJSSURBVFR3Lz3Dok6qG/Q96n5LjwEAXIv8RZ/35u7et325LWYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABjimKUHWEJVnZHkjCQ5PicsPA0AwMq1cotZd5/d3fu6e9+xOW7pcQAAklxLwwwAYCJhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGqO5eeoZFVdUnk3xw6TkO4kZJLlh6iA1kve2cdbY71tvuWG87Z53tzuT1dpvuvvH2hdf6MJusqt7U3fuWnmPTWG87Z53tjvW2O9bbzllnu7OJ682uTACAIYQZAMAQwmy2s5ceYENZbztnne2O9bY71tvOWWe7s3HrzTFmAABD2GIGADCEMAMAGEKYAQAMIcwAAIYQZgAAQ/z/vi7Me0xBeXkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'esta es mi vida.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A3LLCx3ZE0Ls"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> ¿ todavia estan en casa ? <end>\n",
      "Predicted translation: are we still at home now ? <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'¿todavia estan en casa?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DUQVLVqUE1YW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> trata de averiguarlo . <end>\n",
      "Predicted translation: try to figure it out . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wrong translation\n",
    "translate(u'trata de averiguarlo.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RTe5P5ioMJwN"
   },
   "source": [
    "## Next steps\n",
    "\n",
    "* [Download a different dataset](http://www.manythings.org/anki/) to experiment with translations, for example, English to German, or English to French.\n",
    "* Experiment with training on a larger dataset, or using more epochs\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nmt_with_attention.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
